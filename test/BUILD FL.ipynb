{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-21T01:31:26.829303Z",
     "start_time": "2023-06-21T01:31:25.547270Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda\\envs\\DSIM\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import sys\n",
    "sys.path.append('..')\n",
    "from model.RESUNet import MinPool\n",
    "from model.util import cat_tensor, crop_tensor\n",
    "class ResBlock2D(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, padding = 1):\n",
    "        super().__init__()\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size = (3,3), stride = (1,1) , padding = (1,1), bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels,kernel_size = (3,3), stride = (1,1), padding = (1,1), bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.identity_map = nn.Conv2d( in_channels, out_channels, kernel_size = (3,3), stride = (1,1), padding = (1,1))\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "    def forward(self, inputs):\n",
    "        x = inputs.clone().detach()\n",
    "        out = self.layer(x)\n",
    "        residual  = self.identity_map(inputs)\n",
    "        skip = out + residual\n",
    "        return self.relu(skip)\n",
    "\n",
    "class Hourglass2D(nn.Module):\n",
    "    def __init__(self, n, f, bn=None, increase=0):\n",
    "        super(Hourglass2D, self).__init__()\n",
    "        nf = f + increase\n",
    "        self.up1 = ResBlock2D(f, f)\n",
    "        # Lower branch\n",
    "        self.pool1 = nn.MaxPool2d((2,2))\n",
    "        self.low1 = ResBlock2D(f, nf)\n",
    "        self.n = n\n",
    "        # Recursive hourglass2d\n",
    "        if self.n > 1:\n",
    "            self.low2 = Hourglass2D(n-1, nf, bn=bn)\n",
    "        else:\n",
    "            self.low2 = ResBlock2D(nf, nf)\n",
    "        self.low3 = ResBlock2D(nf, f)\n",
    "        self.up2 = nn.Upsample(scale_factor = (2,2), mode='nearest')\n",
    "\n",
    "    def forward(self, x):\n",
    "        up1  = self.up1(x)\n",
    "        pool1 = self.pool1(x)\n",
    "        low1 = self.low1(pool1)\n",
    "        low2 = self.low2(low1)\n",
    "        low3 = self.low3(low2)\n",
    "        up2  = self.up2(low3)\n",
    "        return up1 + up2\n",
    "\n",
    "class DShotConnect2D(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        self.conv_r = nn.Sequential(\n",
    "            nn.Conv2d( in_channels, out_channels, kernel_size = (3,3), stride = (1,1), padding = (1,1) ),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.conv_l = nn.Sequential(\n",
    "            nn.Conv2d( in_channels, out_channels, kernel_size = (3,3), stride = (1,1), padding = (1,1) ),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.conv = nn.Sequential(\n",
    "            nn.BatchNorm2d(2 * out_channels),\n",
    "            nn.Conv2d( 2 * out_channels, out_channels, kernel_size = (3,3), stride = (1,1), padding = (1,1) ),\n",
    "            nn.ReLU(),\n",
    "        )\n",
    "  \n",
    "    def forward(self, inputs):\n",
    "        x_r = self.conv_r(inputs)\n",
    "        x_l = self.conv_l(inputs)\n",
    "        x = torch.cat([x_r, x_l], dim = 1)\n",
    "        x = self.conv(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-21T01:34:28.716610Z",
     "start_time": "2023-06-21T01:34:28.700203Z"
    }
   },
   "outputs": [],
   "source": [
    "class FL2D(nn.Module):\n",
    "    def __init__(\n",
    "                self,\n",
    "                in_channel = 1,\n",
    "                out_channel = 1,\n",
    "                middle_channel = 32, \n",
    "                embed_shape = ( 2, 4),\n",
    "                nstack = 2,\n",
    "                batch_size = 16,\n",
    "                need_return_dict = False\n",
    "        ):\n",
    "        super(FL2D, self).__init__()\n",
    "        self.nstack = nstack\n",
    "        self.batch_size = batch_size\n",
    "        self.embed_shape = embed_shape\n",
    "        self.need_return_dict = need_return_dict\n",
    "        \n",
    "        self.downsample = nn.Sequential(\n",
    "            nn.AvgPool2d(2),\n",
    "            nn.Conv2d(in_channel, middle_channel, kernel_size = (3,3), stride = (1,1), padding = 1)\n",
    "        )\n",
    "        \n",
    "        self.upsample = nn.ConvTranspose2d(out_channel, out_channel, (2,2), (2,2))\n",
    "        self.erode = MinPool(2,2,1)\n",
    "        self.dilate = nn.MaxPool2d(2, stride = 1)\n",
    "        \n",
    "        self.hgs = nn.ModuleList( [\n",
    "            nn.Sequential(\n",
    "                Hourglass2D(4, middle_channel, increase = 32)\n",
    "            ) for i in range(nstack)] \n",
    "        )\n",
    "        \n",
    "        self.features = nn.ModuleList( [\n",
    "                nn.Sequential(\n",
    "                    ResBlock2D(middle_channel, middle_channel),\n",
    "                    DShotConnect2D(middle_channel, middle_channel),\n",
    "                ) for i in range(nstack)\n",
    "        ])\n",
    "        \n",
    "        self.outs = nn.ModuleList( [\n",
    "            DShotConnect2D(middle_channel, middle_channel)  for i in range(nstack)\n",
    "        ])\n",
    "        \n",
    "        self.merge_features = nn.ModuleList( [\n",
    "                DShotConnect2D(middle_channel, middle_channel)  for i in range(nstack - 1)\n",
    "        ] )\n",
    "        self.merge_preds = nn.ModuleList( [ DShotConnect2D(middle_channel, middle_channel) for i in range(nstack - 1)] )\n",
    "        self.final = nn.ModuleList( [ nn.Conv2d(nstack * middle_channel, out_channel, kernel_size = (3,3), stride = (1,1), padding = (1,1) ) for i in range(self.batch_size)] )\n",
    "        # self.final = nn.Conv2d(nstack * middle_channel, out_channel, kernel_size = (3,3), stride = (1,1), padding = (1,1) )\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmod = nn.Sigmoid()\n",
    "        \n",
    "        \n",
    "    \n",
    "    def get_embeding(self, x):\n",
    "        embed_x = crop_tensor(x, self.embed_shape[0], self.embed_shape[1])\n",
    "        # embed_x = embed_x.permute(0, 2, 1, 3, 4)\n",
    "        return embed_x\n",
    "    \n",
    "    def re_build(self, x):\n",
    "        # x = x.permute(0, 2, 1, 3, 4)\n",
    "        x = cat_tensor(x, self.embed_shape[0], self.embed_shape[1])        \n",
    "        return x\n",
    "\n",
    "    def build_results(self,x,y):\n",
    "        return {\n",
    "            \"mask\":x,\n",
    "            'edge':y,\n",
    "        }\n",
    "    def forward(self, x):   \n",
    "        x = self.downsample(x)\n",
    "        B,C,W,H =  x.shape\n",
    "        x_embed = self.get_embeding(x) \n",
    "        batch_item_combined_hm_preds = []\n",
    "        \n",
    "        for batch_index in range(B): \n",
    "            batch_item_x_embed = x_embed[batch_index,:,:,:,:]\n",
    "            combined_hm_preds = []\n",
    "            # print(\"batch_item_x_embed:\", batch_item_x_embed.shape)\n",
    "            \n",
    "            for i in range(self.nstack):\n",
    "                hg = self.hgs[i](batch_item_x_embed)\n",
    "                # print(\"hg:\",hg.size()) \n",
    "                feature = self.features[i](hg)\n",
    "                # print(\"feature:\",feature.size())\n",
    "                preds = self.outs[i](feature)\n",
    "                keys = self.sigmod(preds)\n",
    "                # print(\"preds:\", preds.size())\n",
    "                combined_hm_preds.append( self.relu((preds * hg + feature * hg ) * keys ) )\n",
    "                if i < self.nstack - 1:\n",
    "                    x_embed = x_embed + self.merge_preds[i](preds) + self.merge_features[i](feature)\n",
    "            \n",
    "            x_combine = torch.cat(combined_hm_preds, dim = 1)\n",
    "            x_combine =self.final[batch_index](x_combine)\n",
    "            # print(\"x_combine:\", x_combine.shape)\n",
    "            batch_item_combined_hm_preds.append(x_combine)\n",
    "            \n",
    "        x_combine = torch.stack( batch_item_combined_hm_preds, 0)\n",
    "        # print(\"total:x_combin:\", x_combine.shape)\n",
    "        outp = self.re_build( x_combine )\n",
    "        outp = self.upsample(outp)\n",
    "        edge = nn.functional.pad(outp, (1, 0, 1, 0))\n",
    "        edge = self.dilate(edge) - self.erode(edge)\n",
    "        return self.build_results(outp, edge) if (self.need_return_dict) else (outp, edge)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-21T01:34:29.076273Z",
     "start_time": "2023-06-21T01:34:29.034374Z"
    }
   },
   "outputs": [],
   "source": [
    "model = FL2D(1,1, middle_channel = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-21T01:34:29.331066Z",
     "start_time": "2023-06-21T01:34:29.322053Z"
    }
   },
   "outputs": [],
   "source": [
    "image = torch.zeros((2,1,320,640))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-21T01:34:46.673335Z",
     "start_time": "2023-06-21T01:34:46.426987Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_item_x_embed: torch.Size([8, 1, 80, 80])\n",
      "x_combine: torch.Size([8, 1, 80, 80])\n",
      "batch_item_x_embed: torch.Size([8, 1, 80, 80])\n",
      "x_combine: torch.Size([8, 1, 80, 80])\n",
      "total:x_combin: torch.Size([2, 8, 1, 80, 80])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 320, 640])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(image)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-21T01:45:50.112836Z",
     "start_time": "2023-06-21T01:45:50.095877Z"
    }
   },
   "outputs": [],
   "source": [
    "from model.model import Unet\n",
    "class FL_base(nn.Module):\n",
    "    def __init__(\n",
    "                self,\n",
    "                in_channel = 1,\n",
    "                out_channel = 1,\n",
    "                middle_channel = 1,\n",
    "                embed_shape = ( 2, 4),\n",
    "                batch_size = 16,\n",
    "                need_return_dict = False\n",
    "        ):\n",
    "        super(FL_base, self).__init__()\n",
    "     \n",
    "        self.batch_size = batch_size\n",
    "        self.embed_shape = embed_shape\n",
    "        self.need_return_dict = need_return_dict\n",
    "        \n",
    "        self.downsample = nn.Sequential(\n",
    "            nn.AvgPool2d(2),\n",
    "            nn.Conv2d(in_channel, middle_channel, kernel_size = (3,3), stride = (1,1), padding = 1)\n",
    "        )\n",
    "        self.upsample = nn.ConvTranspose2d(out_channel, out_channel, (2,2), (2,2))\n",
    "        self.erode = MinPool(2,2,1)\n",
    "        self.dilate = nn.MaxPool2d(2, stride = 1)\n",
    "        \n",
    "        # replace your model\n",
    "        ####################################\n",
    "        self.model = Unet(False)\n",
    "        ####################################\n",
    "        \n",
    "        self.final = nn.Conv2d(middle_channel, out_channel, kernel_size = (3,3), stride = (1,1), padding = (1,1) )\n",
    "        self.middle_channel = 1\n",
    "        self.relu = nn.ReLU()\n",
    "        self.sigmod = nn.Sigmoid()\n",
    "        \n",
    "        \n",
    "    \n",
    "    def get_embeding(self, x):\n",
    "        embed_x = crop_tensor(x, self.embed_shape[0], self.embed_shape[1])\n",
    "        # embed_x = embed_x.permute(0, 2, 1, 3, 4)\n",
    "        return embed_x\n",
    "    \n",
    "    def re_build(self, x):\n",
    "        # x = x.permute(0, 2, 1, 3, 4)\n",
    "        x = cat_tensor(x, self.embed_shape[0], self.embed_shape[1])        \n",
    "        return x\n",
    "\n",
    "    def build_results(self,x,y):\n",
    "        return {\n",
    "            \"mask\":x,\n",
    "            'edge':y,\n",
    "        }\n",
    "    def forward(self, x):   \n",
    "        x = self.downsample(x)\n",
    "        B,C,W,H =  x.shape\n",
    "        x_embed = self.get_embeding(x) \n",
    "        batch_item_combined_hm_preds = []\n",
    "        \n",
    "        for batch_index in range(B): \n",
    "\n",
    "            batch_item_x_embed = x_embed[batch_index,:,:,:,:]\n",
    "            # print(batch_item_x_embed.shape)\n",
    "            \n",
    "            #### your forward model here\n",
    "            output, _ = self.model( batch_item_x_embed ) # only for mask not edge, edge will have another way\n",
    "            #### \n",
    "            \n",
    "            if self.middle_channel != 1:\n",
    "                output = self.final[batch_index](output)\n",
    "            batch_item_combined_hm_preds.append(output)\n",
    "            \n",
    "        x_combine = torch.stack( batch_item_combined_hm_preds, 0)\n",
    "        # print(\"total:x_combin:\", x_combine.shape)\n",
    "        outp = self.re_build( x_combine )\n",
    "        outp = self.upsample(outp)\n",
    "        edge = nn.functional.pad(outp, (1, 0, 1, 0))\n",
    "        edge = self.dilate(edge) - self.erode(edge)\n",
    "        return self.build_results(outp, edge) if (self.need_return_dict) else (outp, edge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-21T01:45:50.367413Z",
     "start_time": "2023-06-21T01:45:50.346463Z"
    }
   },
   "outputs": [],
   "source": [
    "model = FL_base(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-21T01:45:51.220131Z",
     "start_time": "2023-06-21T01:45:51.210200Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_image = torch.zeros((2,1,320,640))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-21T01:45:58.604200Z",
     "start_time": "2023-06-21T01:45:58.507458Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([8, 1, 80, 80])\n",
      "torch.Size([8, 1, 80, 80])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 320, 640])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(batch_image)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "DSIM",
   "language": "python",
   "name": "dsim"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

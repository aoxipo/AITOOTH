{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-01T02:10:06.457777Z",
     "start_time": "2023-03-01T02:10:05.388483Z"
    }
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-01T02:12:34.404022Z",
     "start_time": "2023-03-01T02:12:34.390059Z"
    }
   },
   "outputs": [],
   "source": [
    "class ResBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super().__init__()\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.Conv2d(in_channels,out_channels,kernel_size=3, padding=1, stride=stride, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(out_channels, out_channels,kernel_size=3,padding=1, stride=1, bias=False),\n",
    "            nn.BatchNorm2d(out_channels),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "\n",
    "        self.identity_map = nn.Conv2d(in_channels, out_channels,kernel_size=1,stride=stride)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "    def forward(self, inputs):\n",
    "        x = inputs.clone().detach()\n",
    "        out = self.layer(x)\n",
    "        residual  = self.identity_map(inputs)\n",
    "        skip = out + residual\n",
    "        return self.relu(skip)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-01T02:12:50.785220Z",
     "start_time": "2023-03-01T02:12:50.773252Z"
    }
   },
   "outputs": [],
   "source": [
    "class DownSampleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super().__init__()\n",
    "        self.layer = nn.Sequential(\n",
    "            nn.MaxPool2d(2),\n",
    "            ResBlock(in_channels, out_channels)\n",
    "        )\n",
    "\n",
    "    def forward(self, inputs):\n",
    "        return self.layer(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-01T02:16:02.293276Z",
     "start_time": "2023-03-01T02:16:02.282302Z"
    }
   },
   "outputs": [],
   "source": [
    "class UpSampleConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.upsample = nn.Upsample(scale_factor=2, mode=\"bilinear\", align_corners=True)\n",
    "        self.res_block = ResBlock(in_channels + out_channels, out_channels)\n",
    "        \n",
    "    def forward(self, inputs, skip):\n",
    "        x = self.upsample(inputs)\n",
    "        x = torch.cat([x, skip], dim=1)\n",
    "        x = self.res_block(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-01T02:16:02.625414Z",
     "start_time": "2023-03-01T02:16:02.612411Z"
    }
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, input_channel, output_channel, dropout_rate = 0.2):\n",
    "        super().__init__()\n",
    "        self.encoding_layer1_ = ResBlock(input_channel,64)\n",
    "        self.encoding_layer2_ = DownSampleConv(64, 128)\n",
    "        self.encoding_layer3_ = DownSampleConv(128, 256)\n",
    "        self.bridge = DownSampleConv(256, 512)\n",
    "        self.decoding_layer3_ = UpSampleConv(512, 256)\n",
    "        self.decoding_layer2_ = UpSampleConv(256, 128)\n",
    "        self.decoding_layer1_ = UpSampleConv(128, 64)\n",
    "        self.output = nn.Conv2d(64, output_channel, kernel_size=1)\n",
    "        self.dropout = nn.Dropout2d(dropout_rate)\n",
    "        \n",
    "    def forward(self, inputs):\n",
    "        ###################### Enocoder #########################\n",
    "        e1 = self.encoding_layer1_(inputs)\n",
    "        e1 = self.dropout(e1)\n",
    "        e2 = self.encoding_layer2_(e1)\n",
    "        e2 = self.dropout(e2)\n",
    "        e3 = self.encoding_layer3_(e2)\n",
    "        e3 = self.dropout(e3)\n",
    "        \n",
    "        ###################### Bridge #########################\n",
    "        bridge = self.bridge(e3)\n",
    "        bridge = self.dropout(bridge)\n",
    "        \n",
    "        ###################### Decoder #########################\n",
    "        d3 = self.decoding_layer3_(bridge, e3)\n",
    "        d2 = self.decoding_layer2_(d3, e2)\n",
    "        d1 = self.decoding_layer1_(d2, e1)\n",
    "        \n",
    "        ###################### Output #########################\n",
    "        output = self.output(d1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-01T02:24:48.644150Z",
     "start_time": "2023-03-01T02:24:48.550380Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [1, 64, 224, 224]           1,728\n",
      "       BatchNorm2d-2          [1, 64, 224, 224]             128\n",
      "              ReLU-3          [1, 64, 224, 224]               0\n",
      "            Conv2d-4          [1, 64, 224, 224]          36,864\n",
      "       BatchNorm2d-5          [1, 64, 224, 224]             128\n",
      "              ReLU-6          [1, 64, 224, 224]               0\n",
      "            Conv2d-7          [1, 64, 224, 224]             256\n",
      "              ReLU-8          [1, 64, 224, 224]               0\n",
      "          ResBlock-9          [1, 64, 224, 224]               0\n",
      "        Dropout2d-10          [1, 64, 224, 224]               0\n",
      "        MaxPool2d-11          [1, 64, 112, 112]               0\n",
      "           Conv2d-12         [1, 128, 112, 112]          73,728\n",
      "      BatchNorm2d-13         [1, 128, 112, 112]             256\n",
      "             ReLU-14         [1, 128, 112, 112]               0\n",
      "           Conv2d-15         [1, 128, 112, 112]         147,456\n",
      "      BatchNorm2d-16         [1, 128, 112, 112]             256\n",
      "             ReLU-17         [1, 128, 112, 112]               0\n",
      "           Conv2d-18         [1, 128, 112, 112]           8,320\n",
      "             ReLU-19         [1, 128, 112, 112]               0\n",
      "         ResBlock-20         [1, 128, 112, 112]               0\n",
      "   DownSampleConv-21         [1, 128, 112, 112]               0\n",
      "        Dropout2d-22         [1, 128, 112, 112]               0\n",
      "        MaxPool2d-23           [1, 128, 56, 56]               0\n",
      "           Conv2d-24           [1, 256, 56, 56]         294,912\n",
      "      BatchNorm2d-25           [1, 256, 56, 56]             512\n",
      "             ReLU-26           [1, 256, 56, 56]               0\n",
      "           Conv2d-27           [1, 256, 56, 56]         589,824\n",
      "      BatchNorm2d-28           [1, 256, 56, 56]             512\n",
      "             ReLU-29           [1, 256, 56, 56]               0\n",
      "           Conv2d-30           [1, 256, 56, 56]          33,024\n",
      "             ReLU-31           [1, 256, 56, 56]               0\n",
      "         ResBlock-32           [1, 256, 56, 56]               0\n",
      "   DownSampleConv-33           [1, 256, 56, 56]               0\n",
      "        Dropout2d-34           [1, 256, 56, 56]               0\n",
      "        MaxPool2d-35           [1, 256, 28, 28]               0\n",
      "           Conv2d-36           [1, 512, 28, 28]       1,179,648\n",
      "      BatchNorm2d-37           [1, 512, 28, 28]           1,024\n",
      "             ReLU-38           [1, 512, 28, 28]               0\n",
      "           Conv2d-39           [1, 512, 28, 28]       2,359,296\n",
      "      BatchNorm2d-40           [1, 512, 28, 28]           1,024\n",
      "             ReLU-41           [1, 512, 28, 28]               0\n",
      "           Conv2d-42           [1, 512, 28, 28]         131,584\n",
      "             ReLU-43           [1, 512, 28, 28]               0\n",
      "         ResBlock-44           [1, 512, 28, 28]               0\n",
      "   DownSampleConv-45           [1, 512, 28, 28]               0\n",
      "        Dropout2d-46           [1, 512, 28, 28]               0\n",
      "         Upsample-47           [1, 512, 56, 56]               0\n",
      "           Conv2d-48           [1, 256, 56, 56]       1,769,472\n",
      "      BatchNorm2d-49           [1, 256, 56, 56]             512\n",
      "             ReLU-50           [1, 256, 56, 56]               0\n",
      "           Conv2d-51           [1, 256, 56, 56]         589,824\n",
      "      BatchNorm2d-52           [1, 256, 56, 56]             512\n",
      "             ReLU-53           [1, 256, 56, 56]               0\n",
      "           Conv2d-54           [1, 256, 56, 56]         196,864\n",
      "             ReLU-55           [1, 256, 56, 56]               0\n",
      "         ResBlock-56           [1, 256, 56, 56]               0\n",
      "     UpSampleConv-57           [1, 256, 56, 56]               0\n",
      "         Upsample-58         [1, 256, 112, 112]               0\n",
      "           Conv2d-59         [1, 128, 112, 112]         442,368\n",
      "      BatchNorm2d-60         [1, 128, 112, 112]             256\n",
      "             ReLU-61         [1, 128, 112, 112]               0\n",
      "           Conv2d-62         [1, 128, 112, 112]         147,456\n",
      "      BatchNorm2d-63         [1, 128, 112, 112]             256\n",
      "             ReLU-64         [1, 128, 112, 112]               0\n",
      "           Conv2d-65         [1, 128, 112, 112]          49,280\n",
      "             ReLU-66         [1, 128, 112, 112]               0\n",
      "         ResBlock-67         [1, 128, 112, 112]               0\n",
      "     UpSampleConv-68         [1, 128, 112, 112]               0\n",
      "         Upsample-69         [1, 128, 224, 224]               0\n",
      "           Conv2d-70          [1, 64, 224, 224]         110,592\n",
      "      BatchNorm2d-71          [1, 64, 224, 224]             128\n",
      "             ReLU-72          [1, 64, 224, 224]               0\n",
      "           Conv2d-73          [1, 64, 224, 224]          36,864\n",
      "      BatchNorm2d-74          [1, 64, 224, 224]             128\n",
      "             ReLU-75          [1, 64, 224, 224]               0\n",
      "           Conv2d-76          [1, 64, 224, 224]          12,352\n",
      "             ReLU-77          [1, 64, 224, 224]               0\n",
      "         ResBlock-78          [1, 64, 224, 224]               0\n",
      "     UpSampleConv-79          [1, 64, 224, 224]               0\n",
      "           Conv2d-80           [1, 3, 224, 224]             195\n",
      "================================================================\n",
      "Total params: 8,217,539\n",
      "Trainable params: 8,217,539\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 1007.18\n",
      "Params size (MB): 31.35\n",
      "Estimated Total Size (MB): 1039.10\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = Generator(3,3).to(0)\n",
    "summary(model, (3, 224, 224), batch_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-01T02:29:59.299031Z",
     "start_time": "2023-03-01T02:29:59.283539Z"
    }
   },
   "outputs": [],
   "source": [
    "class Critic(nn.Module):\n",
    "    def __init__(self, in_channels=3):\n",
    "        super(Critic, self).__init__()\n",
    "\n",
    "        def critic_block(in_filters, out_filters, normalization=True):\n",
    "            \"\"\"Returns layers of each critic block\"\"\"\n",
    "            layers = [nn.Conv2d(in_filters, out_filters, 4, stride=2, padding=1)]\n",
    "            if normalization:\n",
    "                layers.append(nn.InstanceNorm2d(out_filters))\n",
    "            layers.append(nn.LeakyReLU(0.2, inplace=True))\n",
    "            return layers\n",
    "\n",
    "        self.model = nn.Sequential(\n",
    "            *critic_block(in_channels, 64, normalization=False),\n",
    "            *critic_block(64, 128),\n",
    "            *critic_block(128, 256),\n",
    "            *critic_block(256, 512),\n",
    "            nn.AdaptiveAvgPool2d(1),\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(512, 1)\n",
    "        )\n",
    "    def forward(self, img_input):\n",
    "        output = self.model(img_input)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-01T02:30:17.535948Z",
     "start_time": "2023-03-01T02:30:13.091778Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [1, 64, 112, 112]           3,136\n",
      "         LeakyReLU-2          [1, 64, 112, 112]               0\n",
      "            Conv2d-3           [1, 128, 56, 56]         131,200\n",
      "    InstanceNorm2d-4           [1, 128, 56, 56]               0\n",
      "         LeakyReLU-5           [1, 128, 56, 56]               0\n",
      "            Conv2d-6           [1, 256, 28, 28]         524,544\n",
      "    InstanceNorm2d-7           [1, 256, 28, 28]               0\n",
      "         LeakyReLU-8           [1, 256, 28, 28]               0\n",
      "            Conv2d-9           [1, 512, 14, 14]       2,097,664\n",
      "   InstanceNorm2d-10           [1, 512, 14, 14]               0\n",
      "        LeakyReLU-11           [1, 512, 14, 14]               0\n",
      "AdaptiveAvgPool2d-12             [1, 512, 1, 1]               0\n",
      "          Flatten-13                   [1, 512]               0\n",
      "           Linear-14                     [1, 1]             513\n",
      "================================================================\n",
      "Total params: 2,757,057\n",
      "Trainable params: 2,757,057\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 28.34\n",
      "Params size (MB): 10.52\n",
      "Estimated Total Size (MB): 39.43\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = Critic(3).to(0)\n",
    "summary(model, (3, 224, 224), batch_size = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-03-01T05:58:24.855681Z",
     "start_time": "2023-03-01T05:58:24.842717Z"
    }
   },
   "outputs": [],
   "source": [
    "def _weights_init(m):\n",
    "    if isinstance(m, (nn.Conv2d, nn.ConvTranspose2d)):\n",
    "        torch.nn.init.normal_(m.weight, 0.0, 0.02)\n",
    "    if isinstance(m, nn.BatchNorm2d):\n",
    "        torch.nn.init.normal_(m.weight, 0.0, 0.02)\n",
    "        torch.nn.init.constant_(m.bias, 0)\n",
    "def display_progress(cond, real, fake, current_epoch = 0, figsize=(20,15), save = False, save_path = 'D:'):\n",
    "    \"\"\"\n",
    "    Save cond, real (original) and generated (fake)\n",
    "    images in one panel \n",
    "    \"\"\"\n",
    "    cond = cond.detach().cpu().permute(1, 2, 0)   \n",
    "    real = real.detach().cpu().permute(1, 2, 0)\n",
    "    fake = fake.detach().cpu().permute(1, 2, 0)\n",
    "    \n",
    "    images = [cond, real, fake]\n",
    "    titles = ['input','real','generated']\n",
    "    print(f'Epoch: {current_epoch}')\n",
    "    fig, ax = plt.subplots(1, 3, figsize=figsize)\n",
    "    for idx,img in enumerate(images):\n",
    "        if idx == 0:\n",
    "            ab = torch.zeros((224,224,2))\n",
    "            img = torch.cat([images[0]* 100, ab], dim=2).numpy()\n",
    "            imgan = lab2rgb(img)\n",
    "        else:\n",
    "            imgan = lab_to_rgb(images[0],img)\n",
    "        ax[idx].imshow(imgan)\n",
    "        ax[idx].axis(\"off\")\n",
    "    for idx, title in enumerate(titles):    \n",
    "        ax[idx].set_title('{}'.format(title))\n",
    "    if save:\n",
    "        f = plt.gcf()  #获取当前图像\n",
    "        f.savefig(save_path + '/{}.png'.format(current_epoch))\n",
    "        f.clear()  #释放\n",
    "    else:\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CWGAN(pl.LightningModule):\n",
    "\n",
    "    def __init__(self, in_channels, out_channels, learning_rate=0.0002, lambda_recon=100, display_step=10, lambda_gp=10, lambda_r1=10,):\n",
    "\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        \n",
    "        self.display_step = display_step\n",
    "        \n",
    "        self.generator = Generator(in_channels, out_channels)\n",
    "        self.critic = Critic(in_channels + out_channels)\n",
    "        self.optimizer_G = optim.Adam(self.generator.parameters(), lr=learning_rate, betas=(0.5, 0.9))\n",
    "        self.optimizer_C = optim.Adam(self.critic.parameters(), lr=learning_rate, betas=(0.5, 0.9))\n",
    "        self.lambda_recon = lambda_recon\n",
    "        self.lambda_gp = lambda_gp\n",
    "        self.lambda_r1 = lambda_r1\n",
    "        self.recon_criterion = nn.L1Loss()\n",
    "        self.generator_losses, self.critic_losses  = [],[]\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return [self.optimizer_C, self.optimizer_G]\n",
    "        \n",
    "    def generator_step(self, real_images, conditioned_images):\n",
    "        # WGAN has only a reconstruction loss\n",
    "        self.optimizer_G.zero_grad()\n",
    "        fake_images = self.generator(conditioned_images)\n",
    "        recon_loss = self.recon_criterion(fake_images, real_images)\n",
    "        recon_loss.backward()\n",
    "        self.optimizer_G.step()\n",
    "        \n",
    "        # Keep track of the average generator loss\n",
    "        self.generator_losses += [recon_loss.item()]\n",
    "        \n",
    "        \n",
    "    def critic_step(self, real_images, conditioned_images):\n",
    "        self.optimizer_C.zero_grad()\n",
    "        fake_images = self.generator(conditioned_images)\n",
    "        fake_logits = self.critic(fake_images, conditioned_images)\n",
    "        real_logits = self.critic(real_images, conditioned_images)\n",
    "        \n",
    "        # Compute the loss for the critic\n",
    "        loss_C = real_logits.mean() - fake_logits.mean()\n",
    "\n",
    "        # Compute the gradient penalty\n",
    "        alpha = torch.rand(real_images.size(0), 1, 1, 1, requires_grad=True)\n",
    "        alpha = alpha.to(device)\n",
    "        interpolated = (alpha * real_images + (1 - alpha) * fake_images.detach()).requires_grad_(True)\n",
    "        \n",
    "        interpolated_logits = self.critic(interpolated, conditioned_images)\n",
    "        \n",
    "        grad_outputs = torch.ones_like(interpolated_logits, dtype=torch.float32, requires_grad=True)\n",
    "        gradients = torch.autograd.grad(outputs=interpolated_logits, inputs=interpolated, grad_outputs=grad_outputs,create_graph=True, retain_graph=True)[0]\n",
    "\n",
    "        \n",
    "        gradients = gradients.view(len(gradients), -1)\n",
    "        gradients_penalty = ((gradients.norm(2, dim=1) - 1) ** 2).mean()\n",
    "        loss_C += self.lambda_gp * gradients_penalty\n",
    "        \n",
    "        # Compute the R1 regularization loss\n",
    "        r1_reg = gradients.pow(2).sum(1).mean()\n",
    "        loss_C += self.lambda_r1 * r1_reg\n",
    "\n",
    "        # Backpropagation\n",
    "        loss_C.backward()\n",
    "        self.optimizer_C.step()\n",
    "        self.critic_losses += [loss_C.item()]\n",
    "        \n",
    "    def training_step(self, batch, batch_idx, optimizer_idx):\n",
    "        real, condition = batch\n",
    "        if optimizer_idx == 0:\n",
    "            self.critic_step(real, condition)\n",
    "        elif optimizer_idx == 1:\n",
    "            self.generator_step(real, condition)\n",
    "        gen_mean = sum(self.generator_losses[-self.display_step:]) / self.display_step\n",
    "        crit_mean = sum(self.critic_losses[-self.display_step:]) / self.display_step\n",
    "        if self.current_epoch%self.display_step==0 and batch_idx==0 and optimizer_idx==1:\n",
    "            fake = self.generator(condition).detach()\n",
    "            torch.save(cwgan.generator.state_dict(), \"ResUnet_\"+ str(self.current_epoch) +\".pt\")\n",
    "            torch.save(cwgan.critic.state_dict(), \"PatchGAN_\"+ str(self.current_epoch) +\".pt\")\n",
    "            print(f\"Epoch {self.current_epoch} : Generator loss: {gen_mean}, Critic loss: {crit_mean}\")\n",
    "            display_progress(condition[0], real[0], fake[0], self.current_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(30,60))\n",
    "idx =1\n",
    "for batch_idx, batch in enumerate(test_loader):\n",
    "    real, condition = batch\n",
    "    pred = cwgan.generator(condition).detach().squeeze().permute(1, 2, 0)\n",
    "    condition  = condition.detach().squeeze(0).permute(1, 2, 0)\n",
    "    real  = real.detach().squeeze(0).permute(1, 2, 0)\n",
    "    plt.subplots_adjust(wspace=0, hspace=0)\n",
    "    plt.subplot(6,3,idx)\n",
    "    plt.grid(False)\n",
    "    \n",
    "    ab = torch.zeros((224,224,2))\n",
    "    img = torch.cat([condition * 100, ab], dim=2).numpy()\n",
    "    imgan = lab2rgb(img)\n",
    "    plt.imshow(imgan)\n",
    "    plt.title('Input')\n",
    "    \n",
    "    plt.subplot(6,3,idx + 1)\n",
    "    \n",
    "    ab = torch.zeros((224,224,2))\n",
    "    imgan = lab_to_rgb(condition,real)\n",
    "    plt.imshow(imgan)\n",
    "    plt.title('Real')\n",
    "    \n",
    "    plt.subplot(6,3,idx + 2)\n",
    "    imgan = lab_to_rgb(condition,pred)\n",
    "    plt.title('Generated')\n",
    "    plt.imshow(imgan)\n",
    "    idx += 3\n",
    "    if idx >= 18:\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "DSIM",
   "language": "python",
   "name": "dsim"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

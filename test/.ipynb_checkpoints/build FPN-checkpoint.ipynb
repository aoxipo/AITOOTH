{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-25T11:14:07.358866Z",
     "start_time": "2023-06-25T11:14:05.953504Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda\\envs\\DSIM\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from model.util import MinPool\n",
    "from model.RESUNet import ResBlock\n",
    "from model.model import *\n",
    "from model.util import cat_tensor, crop_tensor\n",
    "from model.model import Unet\n",
    "from model.FL_seris import Encode, Decode\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-25T11:14:07.373776Z",
     "start_time": "2023-06-25T11:14:07.364801Z"
    }
   },
   "outputs": [],
   "source": [
    "class Encode(nn.Module):\n",
    "    def __init__(self, in_channel, out_channel, block_number = 1, conv_type = \"conv\"):\n",
    "        super().__init__( )\n",
    "        if conv_type == \"conv\":\n",
    "            self.conv = RC(in_channel, out_channel, block_number = block_number)\n",
    "        else:\n",
    "            self.conv = RCS(in_channel, out_channel, block_number = block_number)\n",
    "        self.downsample = nn.MaxPool2d(2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x_conv = self.conv(x)\n",
    "        x_pool = self.downsample(x_conv)\n",
    "        return x_conv, x_pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-25T11:14:08.319103Z",
     "start_time": "2023-06-25T11:14:08.295163Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "\n",
    "class FPN(nn.Module):\n",
    "    def __init__(\n",
    "                self,\n",
    "                in_channel = 1,\n",
    "                out_channel = 1,\n",
    "                # block_layers=[6, 12, 24, 16], \n",
    "                # transition_layer = [256, 512, 1024, 1024],\n",
    "                middle_channel = [16, 32, 64, 128],\n",
    "                encode_len = 4,\n",
    "                need_return_dict = False\n",
    "        ):\n",
    "        super(FPN,self).__init__()\n",
    "        self.need_return_dict = need_return_dict\n",
    "        self.downsample = nn.AvgPool2d(2,2)\n",
    "        self.erode = MinPool(2,2,1)\n",
    "        self.dilate = nn.MaxPool2d(2, stride = 1)\n",
    "        middle_channel = middle_channel[ len(middle_channel) - encode_len : ]\n",
    "        index_len = encode_len - 1\n",
    "    \n",
    "        self.pre_encode = nn.Sequential(\n",
    "            Encode(in_channel, middle_channel[0], 4)\n",
    "        )\n",
    "        self.out = nn.Sequential(\n",
    "            nn.Conv2d( middle_channel[0], out_channel,1,1)\n",
    "        )\n",
    "        self.last_decode = Decode(middle_channel[1], middle_channel[0], conv_type = \"conv\") \n",
    "        \n",
    "        self.encode = nn.ModuleList(\n",
    "            [ Encode(\n",
    "                2 * middle_channel[i], \n",
    "                middle_channel[ i+1 ], 2, \n",
    "                conv_type = \"conv\"\n",
    "            )  for i in range(index_len) ]\n",
    "        )\n",
    "        self.decode = nn.ModuleList(\n",
    "            [\n",
    "                Decode(\n",
    "                    2 * middle_channel[index_len - i], \n",
    "                    2 * middle_channel[index_len - i - 1], \n",
    "                    conv_type = \"conv\") \n",
    "                for i in range(index_len)\n",
    "            ]\n",
    "        )\n",
    "        self.CBR = nn.ModuleList()\n",
    "        for i in range(encode_len):\n",
    "            self.CBR.append(\n",
    "                nn.Sequential(\n",
    "                    nn.Conv2d(in_channel, middle_channel[i],3, 1, 1),\n",
    "                    nn.BatchNorm2d(middle_channel[i]),\n",
    "                    nn.ReLU(),\n",
    "                )\n",
    "            )\n",
    "        self.index_len = index_len     \n",
    "        \n",
    "    def build_feature_pyramid(self, x): # 80\n",
    "        x_list = []\n",
    "        x_list.append(x)\n",
    "        for i in range(self.index_len + 1):\n",
    "            x = self.downsample(x) \n",
    "            x_list.append( x )\n",
    "        return   x_list\n",
    "\n",
    "    def feature(self, x):\n",
    "        x_encode_list = []\n",
    "        for i in range(self.index_len + 1):\n",
    "            print(i)\n",
    "            x_encode_list.append( self.CBR[i]( x[ i + 1 ] ) )\n",
    "            print(x_encode_list[-1].shape)\n",
    "        xc_list = []\n",
    "        xp_list = []\n",
    "        \n",
    "        xc_0, xp_0 = self.pre_encode(x[0])\n",
    "        xc_list.append(xc_0)\n",
    "        xp_list.append(xp_0)\n",
    "        \n",
    "        for i in range(self.index_len):\n",
    "            x_cat  = torch.cat([xp_list[i], x_encode_list[i]], 1)\n",
    "            ec, ep = self.encode[i](x_cat)\n",
    "            # print(ec.shape, ep.shape, )\n",
    "            xc_list.append(ec)\n",
    "            xp_list.append(ep)\n",
    "        \n",
    "        x_c = torch.cat([xp_list[-1], x_encode_list[-1]], 1)\n",
    "        # print(\"cat :\", x_c.shape)\n",
    "        xc_list = list(reversed( xc_list ))\n",
    "        \n",
    "        for i in range(self.index_len):\n",
    "            x_c = self.decode[i](x_c, xc_list[i])\n",
    "            # print(\"decode :\", x_c.shape)\n",
    "        \n",
    "        x_c = self.last_decode(x_c, xc_0)\n",
    "        # print(\"decode :\", x_c.shape)\n",
    "        out = self.out(x_c)\n",
    "        edge = nn.functional.pad(out, (1, 0, 1, 0))\n",
    "        edge = self.dilate(edge) - self.erode(edge)\n",
    "        return  out, edge\n",
    "    \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x= self.feature(self.build_feature_pyramid(x))\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-25T11:14:11.540731Z",
     "start_time": "2023-06-25T11:14:11.510738Z"
    }
   },
   "outputs": [],
   "source": [
    "model = FPN(middle_channel = [8,16,32,64,128], encode_len = 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-25T11:17:00.715970Z",
     "start_time": "2023-06-25T11:17:00.709986Z"
    }
   },
   "outputs": [],
   "source": [
    "batch_image = torch.zeros(( 1, 1, 80, 80))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-25T11:17:01.120288Z",
     "start_time": "2023-06-25T11:17:01.110177Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "106.66666666666667"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "320/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-25T11:17:01.959049Z",
     "start_time": "2023-06-25T11:17:01.927021Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "torch.Size([1, 16, 40, 40])\n",
      "1\n",
      "torch.Size([1, 32, 20, 20])\n",
      "2\n",
      "torch.Size([1, 64, 10, 10])\n",
      "3\n",
      "torch.Size([1, 128, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "ans = model(batch_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-25T06:57:50.123831Z",
     "start_time": "2023-06-25T06:57:50.081942Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "torch.Size([2, 32, 40, 40])\n",
      "1\n",
      "torch.Size([2, 64, 20, 20])\n",
      "2\n",
      "torch.Size([2, 128, 10, 10])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "         AvgPool2d-1            [-1, 1, 40, 40]               0\n",
      "         AvgPool2d-2            [-1, 1, 20, 20]               0\n",
      "         AvgPool2d-3            [-1, 1, 10, 10]               0\n",
      "            Conv2d-4           [-1, 32, 40, 40]             320\n",
      "       BatchNorm2d-5           [-1, 32, 40, 40]              64\n",
      "              ReLU-6           [-1, 32, 40, 40]               0\n",
      "            Conv2d-7           [-1, 64, 20, 20]             640\n",
      "       BatchNorm2d-8           [-1, 64, 20, 20]             128\n",
      "              ReLU-9           [-1, 64, 20, 20]               0\n",
      "           Conv2d-10          [-1, 128, 10, 10]           1,280\n",
      "      BatchNorm2d-11          [-1, 128, 10, 10]             256\n",
      "             ReLU-12          [-1, 128, 10, 10]               0\n",
      "           Conv2d-13           [-1, 32, 80, 80]             320\n",
      "           Conv2d-14           [-1, 32, 80, 80]           9,248\n",
      "           Conv2d-15           [-1, 32, 80, 80]           9,248\n",
      "           Conv2d-16           [-1, 32, 80, 80]           9,248\n",
      "               RC-17           [-1, 32, 80, 80]               0\n",
      "        MaxPool2d-18           [-1, 32, 40, 40]               0\n",
      "           Encode-19  [[-1, 32, 80, 80], [-1, 32, 40, 40]]               0\n",
      "           Conv2d-20           [-1, 64, 40, 40]          36,928\n",
      "           Conv2d-21           [-1, 64, 40, 40]          36,928\n",
      "               RC-22           [-1, 64, 40, 40]               0\n",
      "        MaxPool2d-23           [-1, 64, 20, 20]               0\n",
      "           Encode-24  [[-1, 64, 40, 40], [-1, 64, 20, 20]]               0\n",
      "           Conv2d-25          [-1, 128, 20, 20]         147,584\n",
      "           Conv2d-26          [-1, 128, 20, 20]         147,584\n",
      "               RC-27          [-1, 128, 20, 20]               0\n",
      "        MaxPool2d-28          [-1, 128, 10, 10]               0\n",
      "           Encode-29  [[-1, 128, 20, 20], [-1, 128, 10, 10]]               0\n",
      "  ConvTranspose2d-30          [-1, 128, 20, 20]         131,200\n",
      "      BatchNorm2d-31          [-1, 128, 20, 20]             256\n",
      "        LeakyReLU-32          [-1, 128, 20, 20]               0\n",
      "             DCBL-33          [-1, 128, 20, 20]               0\n",
      "           Conv2d-34          [-1, 128, 20, 20]         295,040\n",
      "      BatchNorm2d-35          [-1, 128, 20, 20]             256\n",
      "             ReLU-36          [-1, 128, 20, 20]               0\n",
      "           Conv2d-37          [-1, 128, 20, 20]         147,584\n",
      "      BatchNorm2d-38          [-1, 128, 20, 20]             256\n",
      "             ReLU-39          [-1, 128, 20, 20]               0\n",
      "           Conv2d-40          [-1, 128, 20, 20]          32,896\n",
      "             ReLU-41          [-1, 128, 20, 20]               0\n",
      "         ResBlock-42          [-1, 128, 20, 20]               0\n",
      "           Conv2d-43          [-1, 128, 20, 20]         147,584\n",
      "      BatchNorm2d-44          [-1, 128, 20, 20]             256\n",
      "             ReLU-45          [-1, 128, 20, 20]               0\n",
      "           Conv2d-46          [-1, 128, 20, 20]         147,584\n",
      "      BatchNorm2d-47          [-1, 128, 20, 20]             256\n",
      "             ReLU-48          [-1, 128, 20, 20]               0\n",
      "           Conv2d-49          [-1, 128, 20, 20]          16,512\n",
      "             ReLU-50          [-1, 128, 20, 20]               0\n",
      "         ResBlock-51          [-1, 128, 20, 20]               0\n",
      "              RCS-52          [-1, 128, 20, 20]               0\n",
      "           Decode-53          [-1, 128, 20, 20]               0\n",
      "  ConvTranspose2d-54           [-1, 64, 40, 40]          32,832\n",
      "      BatchNorm2d-55           [-1, 64, 40, 40]             128\n",
      "        LeakyReLU-56           [-1, 64, 40, 40]               0\n",
      "             DCBL-57           [-1, 64, 40, 40]               0\n",
      "           Conv2d-58           [-1, 64, 40, 40]          73,792\n",
      "      BatchNorm2d-59           [-1, 64, 40, 40]             128\n",
      "             ReLU-60           [-1, 64, 40, 40]               0\n",
      "           Conv2d-61           [-1, 64, 40, 40]          36,928\n",
      "      BatchNorm2d-62           [-1, 64, 40, 40]             128\n",
      "             ReLU-63           [-1, 64, 40, 40]               0\n",
      "           Conv2d-64           [-1, 64, 40, 40]           8,256\n",
      "             ReLU-65           [-1, 64, 40, 40]               0\n",
      "         ResBlock-66           [-1, 64, 40, 40]               0\n",
      "           Conv2d-67           [-1, 64, 40, 40]          36,928\n",
      "      BatchNorm2d-68           [-1, 64, 40, 40]             128\n",
      "             ReLU-69           [-1, 64, 40, 40]               0\n",
      "           Conv2d-70           [-1, 64, 40, 40]          36,928\n",
      "      BatchNorm2d-71           [-1, 64, 40, 40]             128\n",
      "             ReLU-72           [-1, 64, 40, 40]               0\n",
      "           Conv2d-73           [-1, 64, 40, 40]           4,160\n",
      "             ReLU-74           [-1, 64, 40, 40]               0\n",
      "         ResBlock-75           [-1, 64, 40, 40]               0\n",
      "              RCS-76           [-1, 64, 40, 40]               0\n",
      "           Decode-77           [-1, 64, 40, 40]               0\n",
      "  ConvTranspose2d-78           [-1, 32, 80, 80]           8,224\n",
      "      BatchNorm2d-79           [-1, 32, 80, 80]              64\n",
      "        LeakyReLU-80           [-1, 32, 80, 80]               0\n",
      "             DCBL-81           [-1, 32, 80, 80]               0\n",
      "           Conv2d-82           [-1, 32, 80, 80]          18,464\n",
      "      BatchNorm2d-83           [-1, 32, 80, 80]              64\n",
      "             ReLU-84           [-1, 32, 80, 80]               0\n",
      "           Conv2d-85           [-1, 32, 80, 80]           9,248\n",
      "      BatchNorm2d-86           [-1, 32, 80, 80]              64\n",
      "             ReLU-87           [-1, 32, 80, 80]               0\n",
      "           Conv2d-88           [-1, 32, 80, 80]           2,080\n",
      "             ReLU-89           [-1, 32, 80, 80]               0\n",
      "         ResBlock-90           [-1, 32, 80, 80]               0\n",
      "           Conv2d-91           [-1, 32, 80, 80]           9,248\n",
      "      BatchNorm2d-92           [-1, 32, 80, 80]              64\n",
      "             ReLU-93           [-1, 32, 80, 80]               0\n",
      "           Conv2d-94           [-1, 32, 80, 80]           9,248\n",
      "      BatchNorm2d-95           [-1, 32, 80, 80]              64\n",
      "             ReLU-96           [-1, 32, 80, 80]               0\n",
      "           Conv2d-97           [-1, 32, 80, 80]           1,056\n",
      "             ReLU-98           [-1, 32, 80, 80]               0\n",
      "         ResBlock-99           [-1, 32, 80, 80]               0\n",
      "             RCS-100           [-1, 32, 80, 80]               0\n",
      "          Decode-101           [-1, 32, 80, 80]               0\n",
      "          Conv2d-102            [-1, 1, 80, 80]              33\n",
      "       MaxPool2d-103            [-1, 1, 80, 80]               0\n",
      "       MaxPool2d-104            [-1, 1, 80, 80]               0\n",
      "         MinPool-105            [-1, 1, 80, 80]               0\n",
      "================================================================\n",
      "Total params: 1,607,841\n",
      "Trainable params: 1,607,841\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.02\n",
      "Forward/backward pass size (MB): 6616.10\n",
      "Params size (MB): 6.13\n",
      "Estimated Total Size (MB): 6622.26\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model.cuda(), (1,80,80))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-25T06:53:02.046371Z",
     "start_time": "2023-06-25T06:53:02.035474Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 160, 160])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ans[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-25T02:34:46.952716Z",
     "start_time": "2023-06-25T02:34:46.943649Z"
    }
   },
   "outputs": [],
   "source": [
    "a = [0.16820919930934905, 0.11555813759565353, 0.10406000860035419, 0.09637853257358074, 0.09082919470965863, 0.08597795620560646, 0.08181536719202995, 0.07813958384096623, 0.07437959440052509, 0.07080989994108677, 0.06790822520852088, 0.0651423578336835, 0.06234778765588999, 0.05975172657519579, 0.05761727601289749, 0.0554961309209466, 0.05328702192753553, 0.05152266371995211, 0.050051631219685075, 0.048332386501133445, 0.04696276798844337, 0.04537936400622129, 0.044138674549758436, 0.04291338182985783, 0.04156916078180075, 0.04070404600352049, 0.03959252323955297, 0.038757648505270484, 0.037821538373827936, 0.03702100329101086, 0.036216543540358546, 0.035624408610165116, 0.03498207278549671, 0.03414684461429715, 0.033567180875688794, 0.03290734075009823, 0.03242268029600382, 0.03188748175278306, 0.031559570580720904, 0.03112207241356373, 0.030761862453073264, 0.030335290562361478, 0.029909557178616524, 0.029660565312951803, 0.029230893459171056, 0.028874552380293607, 0.028548107556998728, 0.028311173133552074, 0.028025481533259154, 0.027650082129985095, 0.027576511520892383, 0.02735332813113928, 0.027140375636518003, 0.026942391190677883, 0.026719382479786873, 0.02650448229163885, 0.026182646062225104, 0.026366023905575277, 0.025947123821824788, 0.0257209007255733, 0.025685580223798753, 0.025583725329488514, 0.025302596911787986, 0.025257541853934525, 0.025111505798995494, 0.024911839812994004, 0.02482968198135495, 0.024761652015149592, 0.02465659558773041, 0.024481285382062196, 0.024310764838010073, 0.024279800951480867, 0.024063430037349464, 0.023906650431454183, 0.024009056072682142, 0.02399568434804678, 0.023833607267588378, 0.023892152924090623, 0.02363531494513154]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-06-25T02:34:52.061964Z",
     "start_time": "2023-06-25T02:34:52.047998Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.028025481533259154"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[48]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "DSIM",
   "language": "python",
   "name": "dsim"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

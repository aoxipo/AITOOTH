{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-24T12:25:43.093004Z",
     "start_time": "2023-02-24T12:25:41.599795Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda\\envs\\DSIM\\lib\\site-packages\\tqdm\\auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-24T12:25:44.595910Z",
     "start_time": "2023-02-24T12:25:44.570889Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "Pool = nn.MaxPool2d\n",
    "\n",
    "def batchnorm(x):\n",
    "    return nn.BatchNorm2d(x.size()[1])(x)\n",
    "\n",
    "class Conv(nn.Module):\n",
    "    def __init__(self, inp_dim, out_dim, kernel_size=3, stride = 1, bn = False, relu = True):\n",
    "        super(Conv, self).__init__()\n",
    "        self.inp_dim = inp_dim\n",
    "        self.conv = nn.Conv2d(inp_dim, out_dim, kernel_size, stride, padding=(kernel_size-1)//2, bias=True)\n",
    "        self.relu = None\n",
    "        self.bn = None\n",
    "        if relu:\n",
    "            self.relu = nn.ReLU()\n",
    "        if bn:\n",
    "            self.bn = nn.BatchNorm2d(out_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        assert x.size()[1] == self.inp_dim, \"{} {}\".format(x.size()[1], self.inp_dim)\n",
    "        x = self.conv(x)\n",
    "        if self.bn is not None:\n",
    "            x = self.bn(x)\n",
    "        if self.relu is not None:\n",
    "            x = self.relu(x)\n",
    "        return x\n",
    "    \n",
    "class DWConv(nn.Module):\n",
    "    def __init__(self, inp_dim, out_dim, kernel_size=3, stride = 1, bn = False, relu = True):\n",
    "        super(DWConv, self).__init__()\n",
    "        self.inp_dim = inp_dim\n",
    "        self.depthwise = nn.Conv2d(inp_dim, inp_dim, kernel_size, stride, padding=(kernel_size-1)//2, groups=inp_dim,bias=inp_dim)\n",
    "        self.pointwise = nn.Conv2d(inp_dim, out_dim, kernel_size=1, groups=1)\n",
    "        self.relu = None\n",
    "        self.bn = None\n",
    "        if relu:\n",
    "            self.relu = nn.ReLU()\n",
    "        if bn:\n",
    "            self.bn = nn.BatchNorm2d(out_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        assert x.size()[1] == self.inp_dim, \"{} {}\".format(x.size()[1], self.inp_dim)\n",
    "        x = self.depthwise(x)\n",
    "        x = self.pointwise(x)\n",
    "        if self.bn is not None:\n",
    "            x = self.bn(x)\n",
    "        if self.relu is not None:\n",
    "            x = self.relu(x)\n",
    "        return x\n",
    "class depthwise_separable_conv(nn.Module):\n",
    "    def init(self, nin, nout, kernel_size=3, stride = 1, bn = False, relu = True):\n",
    "        super(depthwise_separable_conv, self).init()\n",
    "        self.depthwise = nn.Conv2d(nin, nin, kernel_size=3, padding=1, groups=nin)\n",
    "        self.pointwise = nn.Conv2d(nin, nout, kernel_size=1)\n",
    "    def forward(self, x):\n",
    "        out = self.depthwise(x)\n",
    "        out = self.pointwise(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "class Residual(nn.Module):\n",
    "    def __init__(self, inp_dim, out_dim, Conv_method = Conv):\n",
    "        super(Residual, self).__init__()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.bn1 = nn.BatchNorm2d(inp_dim)\n",
    "        middle_dim = 1 if int(out_dim/2) <= 0 else int(out_dim/2)\n",
    "        self.conv1 = Conv(inp_dim, middle_dim, 1, relu=False)\n",
    "        self.bn2 = nn.BatchNorm2d(middle_dim)\n",
    "        self.conv2 = Conv_method(middle_dim, middle_dim, 3, relu=False)\n",
    "        self.bn3 = nn.BatchNorm2d(middle_dim)\n",
    "        self.conv3 = Conv(middle_dim, out_dim, 1, relu=False)\n",
    "        self.skip_layer = Conv(inp_dim, out_dim, 1, relu=False)\n",
    "        if inp_dim == out_dim:\n",
    "            self.need_skip = False\n",
    "        else:\n",
    "            self.need_skip = True\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if self.need_skip:\n",
    "            residual = self.skip_layer(x)\n",
    "        else:\n",
    "            residual = x\n",
    "        out = self.bn1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv1(out)\n",
    "        out = self.bn2(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn3(out)\n",
    "        out = self.relu(out)\n",
    "        out = self.conv3(out)\n",
    "        out += residual\n",
    "        return out \n",
    "\n",
    "def conv1x1(in_channels, out_channels, groups=1):\n",
    "    return nn.Sequential(nn.Conv2d(\n",
    "        in_channels,\n",
    "        out_channels,\n",
    "        kernel_size=1,\n",
    "        groups=groups,\n",
    "        stride=1),\n",
    "    nn.BatchNorm2d(out_channels))\n",
    "\n",
    "class Hourglass(nn.Module):\n",
    "    def __init__(self, n, f, bn=None, increase=0):\n",
    "        super(Hourglass, self).__init__()\n",
    "        nf = f + increase\n",
    "        self.up1 = Residual(f, f)\n",
    "        # Lower branch\n",
    "        self.pool1 = Pool(2, 2)\n",
    "        self.low1 = Residual(f, nf)\n",
    "        self.n = n\n",
    "        # Recursive hourglass\n",
    "        if self.n > 1:\n",
    "            self.low2 = Hourglass(n-1, nf, bn=bn)\n",
    "        else:\n",
    "            self.low2 = Residual(nf, nf)\n",
    "        self.low3 = Residual(nf, f)\n",
    "        self.up2 = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "\n",
    "    def forward(self, x):\n",
    "        up1  = self.up1(x)\n",
    "        pool1 = self.pool1(x)\n",
    "        low1 = self.low1(pool1)\n",
    "        low2 = self.low2(low1)\n",
    "        low3 = self.low3(low2)\n",
    "        up2  = self.up2(low3)\n",
    "        return up1 + up2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-25T07:44:11.183336Z",
     "start_time": "2023-02-25T07:44:11.159400Z"
    }
   },
   "outputs": [],
   "source": [
    "class Merge(nn.Module):\n",
    "    def __init__(self, x_dim, y_dim):\n",
    "        super(Merge, self).__init__()\n",
    "        self.conv = Conv(x_dim, y_dim, 1, relu=False, bn=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x)\n",
    "class HeatmapLoss(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    loss for detection heatmap\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super(HeatmapLoss, self).__init__()\n",
    "\n",
    "    def forward(self, pred, gt):\n",
    "        l = ((pred - gt)**2)\n",
    "        l = l.mean(dim=3).mean(dim=2).mean(dim=1)\n",
    "        return l ## l of dim bsize\n",
    "    \n",
    "class ResUnetBlock(torch.nn.Module):\n",
    "    def __init__(self,nstack, inp_dim, oup_dim, bn, increase, conv_api):\n",
    "        super(ResUnetBlock, self).__init__()\n",
    "        self.hgs = nn.ModuleList( [\n",
    "            nn.Sequential(\n",
    "            Hourglass(4, inp_dim, bn, increase),\n",
    "        ) for i in range(nstack)] )\n",
    "        self.features = nn.ModuleList( [\n",
    "            nn.Sequential(\n",
    "            Residual(inp_dim, inp_dim, conv_api),\n",
    "            conv_api(inp_dim, inp_dim, 1, bn=True, relu=True)\n",
    "        ) for i in range(nstack)] )\n",
    "        self.outs = nn.ModuleList( [conv_api(inp_dim, oup_dim, 1, relu=False, bn=False) for i in range(nstack)] )\n",
    "        self.nstack = nstack\n",
    "    def forward(self, x):\n",
    "        combined_hm_preds = []\n",
    "        for i in range(self.nstack):\n",
    "            hg = self.hgs[i](x)\n",
    "            #print(\"hg:\",hg.size())\n",
    "            feature = self.features[i](hg)\n",
    "            #print(\"feature:\",feature.size())\n",
    "            preds = self.outs[i](feature)\n",
    "            #print(\"preds:\", preds.size())\n",
    "            combined_hm_preds.append(preds)\n",
    "        return combined_hm_preds \n",
    "    \n",
    "class RESUNet(nn.Module):\n",
    "    def __init__(self, nstack, inp_dim, oup_dim, Conv_method = \"Conv\",image_shape = (1,256,256),bn=False, increase=0, **kwargs):\n",
    "        super(RESUNet, self).__init__()\n",
    "        self.Conv_method = Conv_method\n",
    "        self.image_shape = image_shape\n",
    "        self.nstack = nstack\n",
    "        self.inp_dim = inp_dim \n",
    "        self.oup_dim = oup_dim\n",
    "        self.conv_type_dict = {\n",
    "            \"DWConv\":DWConv,\n",
    "            \"Conv\":Conv,\n",
    "        }\n",
    "        print(\"using :\",Conv_method)\n",
    "        self.pre = nn.Sequential(\n",
    "            self.conv_type_dict[self.Conv_method](image_shape[0], 64, 7, 2, bn=True, relu=True),\n",
    "            Residual(64, 128, self.conv_type_dict[self.Conv_method]),\n",
    "            Pool(2, 2),\n",
    "            #Residual(64, 128, self.conv_type_dict[self.Conv_method]),\n",
    "            Residual(128,128, self.conv_type_dict[self.Conv_method]),\n",
    "        )\n",
    "        self.break_up = Residual(128, 1, self.conv_type_dict[self.Conv_method])\n",
    "        self.hgs_r_pip = ResUnetBlock(nstack, inp_dim, oup_dim, bn, increase, self.conv_type_dict[self.Conv_method])\n",
    "        self.hgs_g_pip = ResUnetBlock(nstack, inp_dim, oup_dim, bn, increase, self.conv_type_dict[self.Conv_method])\n",
    "        self.hgs_b_pip = ResUnetBlock(nstack, inp_dim, oup_dim, bn, increase, self.conv_type_dict[self.Conv_method])\n",
    "        \n",
    "        #self.merge_features = nn.ModuleList( [Merge(inp_dim, inp_dim) for i in range(nstack-1)] )\n",
    "        #self.merge_preds = nn.ModuleList( [Merge(oup_dim, inp_dim) for i in range(nstack-1)] )\n",
    "        \n",
    "        self.merge = nn.ModuleList( [\n",
    "            nn.Sequential(\n",
    "            nn.Conv2d(nstack*128,9,2,2),\n",
    "            nn.Conv2d(9,9,2,2)\n",
    "        ) for i in range(3)] )\n",
    "        \n",
    "        self.head = nn.ModuleList( \n",
    "            [nn.Sequential( nn.Conv2d(9,1,1,1) ) for i in range(3)]\n",
    "        )\n",
    "        self.nstack = nstack\n",
    "        self.heatmapLoss = HeatmapLoss()\n",
    "        self.up = nn.Upsample(scale_factor=4, mode='bicubic')\n",
    "        \n",
    "    def forward(self, imgs):\n",
    "        ## our posenet\n",
    "        P,C,W,H = imgs.size()\n",
    "\n",
    "        if( C == 1 or C == 3):\n",
    "            x = imgs\n",
    "        else:\n",
    "            x = imgs.permute(0, 3, 1, 2) #x of size 1,3,inpdim,inpdim\n",
    "            \n",
    "        x_backup = x\n",
    "        x_origin = x \n",
    "        x = self.pre(x)\n",
    "        x = self.break_up(x)\n",
    "        #print('res:',x.size())\n",
    "        combined_hm_preds = []\n",
    "        r = self.hgs_r_pip(x_backup)\n",
    "        g = self.hgs_g_pip(x_backup)\n",
    "        b = self.hgs_b_pip(x_backup)\n",
    "        \n",
    "        r_multi_map = torch.cat(r, 1)\n",
    "        g_multi_map = torch.cat(g, 1)\n",
    "        b_multi_map = torch.cat(b, 1)\n",
    "        \n",
    "        \n",
    "        r_multi_map = self.merge[0](r_multi_map)\n",
    "        g_multi_map = self.merge[1](g_multi_map)\n",
    "        b_multi_map = self.merge[2](b_multi_map)\n",
    "        \n",
    "        r_attention_map = torch.mul(r_multi_map,x)\n",
    "        g_attention_map = torch.mul(g_multi_map,x)\n",
    "        b_attention_map = torch.mul(b_multi_map,x)\n",
    "        #print(r_attention_map.size())\n",
    "        color_r_offset = self.head[0](r_attention_map)\n",
    "        color_g_offset = self.head[1](g_attention_map)\n",
    "        color_b_offset = self.head[2](b_attention_map)\n",
    "        color_offset = torch.cat([color_r_offset, color_g_offset, color_b_offset],1)\n",
    "        x_color = self.up(color_offset)\n",
    "        #print(x_color.size())\n",
    "        return x_color #torch.stack(combined_hm_preds, 1)\n",
    "\n",
    "    def calc_loss(self, combined_hm_preds, heatmaps):\n",
    "        combined_loss = []\n",
    "        for i in range(self.nstack):\n",
    "            combined_loss.append(self.heatmapLoss(combined_hm_preds[0][:,i], heatmaps))\n",
    "        combined_loss = torch.stack(combined_loss, dim=1)\n",
    "        return combined_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-25T07:44:11.856043Z",
     "start_time": "2023-02-25T07:44:11.845753Z"
    }
   },
   "outputs": [],
   "source": [
    "image = torch.zeros(1,3,224,224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-25T07:44:12.467026Z",
     "start_time": "2023-02-25T07:44:12.198196Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using : Conv\n"
     ]
    }
   ],
   "source": [
    "model = RESUNet(2, 3, 128, Conv_method = \"Conv\",image_shape = (3,224,224),bn=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-25T07:44:13.064788Z",
     "start_time": "2023-02-25T07:44:12.742291Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res: torch.Size([1, 1, 56, 56])\n",
      "torch.Size([1, 9, 56, 56])\n",
      "torch.Size([1, 3, 224, 224])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3, 224, 224])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(image).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-02-23T09:31:45.713017Z",
     "start_time": "2023-02-23T09:31:32.343602Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "res: torch.Size([2, 1, 56, 56])\n",
      "hg: torch.Size([2, 1, 224, 224])\n",
      "feature: torch.Size([2, 1, 224, 224])\n",
      "preds: torch.Size([2, 128, 224, 224])\n",
      "hg: torch.Size([2, 1, 224, 224])\n",
      "feature: torch.Size([2, 1, 224, 224])\n",
      "preds: torch.Size([2, 128, 224, 224])\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           3,200\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "              Conv-4         [-1, 64, 112, 112]               0\n",
      "            Conv2d-5        [-1, 128, 112, 112]           8,320\n",
      "              Conv-6        [-1, 128, 112, 112]               0\n",
      "       BatchNorm2d-7         [-1, 64, 112, 112]             128\n",
      "              ReLU-8         [-1, 64, 112, 112]               0\n",
      "            Conv2d-9         [-1, 64, 112, 112]           4,160\n",
      "             Conv-10         [-1, 64, 112, 112]               0\n",
      "      BatchNorm2d-11         [-1, 64, 112, 112]             128\n",
      "             ReLU-12         [-1, 64, 112, 112]               0\n",
      "           Conv2d-13         [-1, 64, 112, 112]          36,928\n",
      "             Conv-14         [-1, 64, 112, 112]               0\n",
      "      BatchNorm2d-15         [-1, 64, 112, 112]             128\n",
      "             ReLU-16         [-1, 64, 112, 112]               0\n",
      "           Conv2d-17        [-1, 128, 112, 112]           8,320\n",
      "             Conv-18        [-1, 128, 112, 112]               0\n",
      "         Residual-19        [-1, 128, 112, 112]               0\n",
      "        MaxPool2d-20          [-1, 128, 56, 56]               0\n",
      "      BatchNorm2d-21          [-1, 128, 56, 56]             256\n",
      "             ReLU-22          [-1, 128, 56, 56]               0\n",
      "           Conv2d-23           [-1, 64, 56, 56]           8,256\n",
      "             Conv-24           [-1, 64, 56, 56]               0\n",
      "      BatchNorm2d-25           [-1, 64, 56, 56]             128\n",
      "             ReLU-26           [-1, 64, 56, 56]               0\n",
      "           Conv2d-27           [-1, 64, 56, 56]          36,928\n",
      "             Conv-28           [-1, 64, 56, 56]               0\n",
      "      BatchNorm2d-29           [-1, 64, 56, 56]             128\n",
      "             ReLU-30           [-1, 64, 56, 56]               0\n",
      "           Conv2d-31          [-1, 128, 56, 56]           8,320\n",
      "             Conv-32          [-1, 128, 56, 56]               0\n",
      "         Residual-33          [-1, 128, 56, 56]               0\n",
      "           Conv2d-34            [-1, 1, 56, 56]             129\n",
      "             Conv-35            [-1, 1, 56, 56]               0\n",
      "      BatchNorm2d-36          [-1, 128, 56, 56]             256\n",
      "             ReLU-37          [-1, 128, 56, 56]               0\n",
      "           Conv2d-38            [-1, 1, 56, 56]             129\n",
      "             Conv-39            [-1, 1, 56, 56]               0\n",
      "      BatchNorm2d-40            [-1, 1, 56, 56]               2\n",
      "             ReLU-41            [-1, 1, 56, 56]               0\n",
      "           Conv2d-42            [-1, 1, 56, 56]              10\n",
      "             Conv-43            [-1, 1, 56, 56]               0\n",
      "      BatchNorm2d-44            [-1, 1, 56, 56]               2\n",
      "             ReLU-45            [-1, 1, 56, 56]               0\n",
      "           Conv2d-46            [-1, 1, 56, 56]               2\n",
      "             Conv-47            [-1, 1, 56, 56]               0\n",
      "         Residual-48            [-1, 1, 56, 56]               0\n",
      "      BatchNorm2d-49          [-1, 1, 224, 224]               2\n",
      "             ReLU-50          [-1, 1, 224, 224]               0\n",
      "           Conv2d-51          [-1, 1, 224, 224]               2\n",
      "             Conv-52          [-1, 1, 224, 224]               0\n",
      "      BatchNorm2d-53          [-1, 1, 224, 224]               2\n",
      "             ReLU-54          [-1, 1, 224, 224]               0\n",
      "           Conv2d-55          [-1, 1, 224, 224]              10\n",
      "             Conv-56          [-1, 1, 224, 224]               0\n",
      "      BatchNorm2d-57          [-1, 1, 224, 224]               2\n",
      "             ReLU-58          [-1, 1, 224, 224]               0\n",
      "           Conv2d-59          [-1, 1, 224, 224]               2\n",
      "             Conv-60          [-1, 1, 224, 224]               0\n",
      "         Residual-61          [-1, 1, 224, 224]               0\n",
      "        MaxPool2d-62          [-1, 1, 112, 112]               0\n",
      "      BatchNorm2d-63          [-1, 1, 112, 112]               2\n",
      "             ReLU-64          [-1, 1, 112, 112]               0\n",
      "           Conv2d-65          [-1, 1, 112, 112]               2\n",
      "             Conv-66          [-1, 1, 112, 112]               0\n",
      "      BatchNorm2d-67          [-1, 1, 112, 112]               2\n",
      "             ReLU-68          [-1, 1, 112, 112]               0\n",
      "           Conv2d-69          [-1, 1, 112, 112]              10\n",
      "             Conv-70          [-1, 1, 112, 112]               0\n",
      "      BatchNorm2d-71          [-1, 1, 112, 112]               2\n",
      "             ReLU-72          [-1, 1, 112, 112]               0\n",
      "           Conv2d-73          [-1, 1, 112, 112]               2\n",
      "             Conv-74          [-1, 1, 112, 112]               0\n",
      "         Residual-75          [-1, 1, 112, 112]               0\n",
      "      BatchNorm2d-76          [-1, 1, 112, 112]               2\n",
      "             ReLU-77          [-1, 1, 112, 112]               0\n",
      "           Conv2d-78          [-1, 1, 112, 112]               2\n",
      "             Conv-79          [-1, 1, 112, 112]               0\n",
      "      BatchNorm2d-80          [-1, 1, 112, 112]               2\n",
      "             ReLU-81          [-1, 1, 112, 112]               0\n",
      "           Conv2d-82          [-1, 1, 112, 112]              10\n",
      "             Conv-83          [-1, 1, 112, 112]               0\n",
      "      BatchNorm2d-84          [-1, 1, 112, 112]               2\n",
      "             ReLU-85          [-1, 1, 112, 112]               0\n",
      "           Conv2d-86          [-1, 1, 112, 112]               2\n",
      "             Conv-87          [-1, 1, 112, 112]               0\n",
      "         Residual-88          [-1, 1, 112, 112]               0\n",
      "        MaxPool2d-89            [-1, 1, 56, 56]               0\n",
      "      BatchNorm2d-90            [-1, 1, 56, 56]               2\n",
      "             ReLU-91            [-1, 1, 56, 56]               0\n",
      "           Conv2d-92            [-1, 1, 56, 56]               2\n",
      "             Conv-93            [-1, 1, 56, 56]               0\n",
      "      BatchNorm2d-94            [-1, 1, 56, 56]               2\n",
      "             ReLU-95            [-1, 1, 56, 56]               0\n",
      "           Conv2d-96            [-1, 1, 56, 56]              10\n",
      "             Conv-97            [-1, 1, 56, 56]               0\n",
      "      BatchNorm2d-98            [-1, 1, 56, 56]               2\n",
      "             ReLU-99            [-1, 1, 56, 56]               0\n",
      "          Conv2d-100            [-1, 1, 56, 56]               2\n",
      "            Conv-101            [-1, 1, 56, 56]               0\n",
      "        Residual-102            [-1, 1, 56, 56]               0\n",
      "     BatchNorm2d-103            [-1, 1, 56, 56]               2\n",
      "            ReLU-104            [-1, 1, 56, 56]               0\n",
      "          Conv2d-105            [-1, 1, 56, 56]               2\n",
      "            Conv-106            [-1, 1, 56, 56]               0\n",
      "     BatchNorm2d-107            [-1, 1, 56, 56]               2\n",
      "            ReLU-108            [-1, 1, 56, 56]               0\n",
      "          Conv2d-109            [-1, 1, 56, 56]              10\n",
      "            Conv-110            [-1, 1, 56, 56]               0\n",
      "     BatchNorm2d-111            [-1, 1, 56, 56]               2\n",
      "            ReLU-112            [-1, 1, 56, 56]               0\n",
      "          Conv2d-113            [-1, 1, 56, 56]               2\n",
      "            Conv-114            [-1, 1, 56, 56]               0\n",
      "        Residual-115            [-1, 1, 56, 56]               0\n",
      "       MaxPool2d-116            [-1, 1, 28, 28]               0\n",
      "     BatchNorm2d-117            [-1, 1, 28, 28]               2\n",
      "            ReLU-118            [-1, 1, 28, 28]               0\n",
      "          Conv2d-119            [-1, 1, 28, 28]               2\n",
      "            Conv-120            [-1, 1, 28, 28]               0\n",
      "     BatchNorm2d-121            [-1, 1, 28, 28]               2\n",
      "            ReLU-122            [-1, 1, 28, 28]               0\n",
      "          Conv2d-123            [-1, 1, 28, 28]              10\n",
      "            Conv-124            [-1, 1, 28, 28]               0\n",
      "     BatchNorm2d-125            [-1, 1, 28, 28]               2\n",
      "            ReLU-126            [-1, 1, 28, 28]               0\n",
      "          Conv2d-127            [-1, 1, 28, 28]               2\n",
      "            Conv-128            [-1, 1, 28, 28]               0\n",
      "        Residual-129            [-1, 1, 28, 28]               0\n",
      "     BatchNorm2d-130            [-1, 1, 28, 28]               2\n",
      "            ReLU-131            [-1, 1, 28, 28]               0\n",
      "          Conv2d-132            [-1, 1, 28, 28]               2\n",
      "            Conv-133            [-1, 1, 28, 28]               0\n",
      "     BatchNorm2d-134            [-1, 1, 28, 28]               2\n",
      "            ReLU-135            [-1, 1, 28, 28]               0\n",
      "          Conv2d-136            [-1, 1, 28, 28]              10\n",
      "            Conv-137            [-1, 1, 28, 28]               0\n",
      "     BatchNorm2d-138            [-1, 1, 28, 28]               2\n",
      "            ReLU-139            [-1, 1, 28, 28]               0\n",
      "          Conv2d-140            [-1, 1, 28, 28]               2\n",
      "            Conv-141            [-1, 1, 28, 28]               0\n",
      "        Residual-142            [-1, 1, 28, 28]               0\n",
      "       MaxPool2d-143            [-1, 1, 14, 14]               0\n",
      "     BatchNorm2d-144            [-1, 1, 14, 14]               2\n",
      "            ReLU-145            [-1, 1, 14, 14]               0\n",
      "          Conv2d-146            [-1, 1, 14, 14]               2\n",
      "            Conv-147            [-1, 1, 14, 14]               0\n",
      "     BatchNorm2d-148            [-1, 1, 14, 14]               2\n",
      "            ReLU-149            [-1, 1, 14, 14]               0\n",
      "          Conv2d-150            [-1, 1, 14, 14]              10\n",
      "            Conv-151            [-1, 1, 14, 14]               0\n",
      "     BatchNorm2d-152            [-1, 1, 14, 14]               2\n",
      "            ReLU-153            [-1, 1, 14, 14]               0\n",
      "          Conv2d-154            [-1, 1, 14, 14]               2\n",
      "            Conv-155            [-1, 1, 14, 14]               0\n",
      "        Residual-156            [-1, 1, 14, 14]               0\n",
      "     BatchNorm2d-157            [-1, 1, 14, 14]               2\n",
      "            ReLU-158            [-1, 1, 14, 14]               0\n",
      "          Conv2d-159            [-1, 1, 14, 14]               2\n",
      "            Conv-160            [-1, 1, 14, 14]               0\n",
      "     BatchNorm2d-161            [-1, 1, 14, 14]               2\n",
      "            ReLU-162            [-1, 1, 14, 14]               0\n",
      "          Conv2d-163            [-1, 1, 14, 14]              10\n",
      "            Conv-164            [-1, 1, 14, 14]               0\n",
      "     BatchNorm2d-165            [-1, 1, 14, 14]               2\n",
      "            ReLU-166            [-1, 1, 14, 14]               0\n",
      "          Conv2d-167            [-1, 1, 14, 14]               2\n",
      "            Conv-168            [-1, 1, 14, 14]               0\n",
      "        Residual-169            [-1, 1, 14, 14]               0\n",
      "     BatchNorm2d-170            [-1, 1, 14, 14]               2\n",
      "            ReLU-171            [-1, 1, 14, 14]               0\n",
      "          Conv2d-172            [-1, 1, 14, 14]               2\n",
      "            Conv-173            [-1, 1, 14, 14]               0\n",
      "     BatchNorm2d-174            [-1, 1, 14, 14]               2\n",
      "            ReLU-175            [-1, 1, 14, 14]               0\n",
      "          Conv2d-176            [-1, 1, 14, 14]              10\n",
      "            Conv-177            [-1, 1, 14, 14]               0\n",
      "     BatchNorm2d-178            [-1, 1, 14, 14]               2\n",
      "            ReLU-179            [-1, 1, 14, 14]               0\n",
      "          Conv2d-180            [-1, 1, 14, 14]               2\n",
      "            Conv-181            [-1, 1, 14, 14]               0\n",
      "        Residual-182            [-1, 1, 14, 14]               0\n",
      "        Upsample-183            [-1, 1, 28, 28]               0\n",
      "       Hourglass-184            [-1, 1, 28, 28]               0\n",
      "     BatchNorm2d-185            [-1, 1, 28, 28]               2\n",
      "            ReLU-186            [-1, 1, 28, 28]               0\n",
      "          Conv2d-187            [-1, 1, 28, 28]               2\n",
      "            Conv-188            [-1, 1, 28, 28]               0\n",
      "     BatchNorm2d-189            [-1, 1, 28, 28]               2\n",
      "            ReLU-190            [-1, 1, 28, 28]               0\n",
      "          Conv2d-191            [-1, 1, 28, 28]              10\n",
      "            Conv-192            [-1, 1, 28, 28]               0\n",
      "     BatchNorm2d-193            [-1, 1, 28, 28]               2\n",
      "            ReLU-194            [-1, 1, 28, 28]               0\n",
      "          Conv2d-195            [-1, 1, 28, 28]               2\n",
      "            Conv-196            [-1, 1, 28, 28]               0\n",
      "        Residual-197            [-1, 1, 28, 28]               0\n",
      "        Upsample-198            [-1, 1, 56, 56]               0\n",
      "       Hourglass-199            [-1, 1, 56, 56]               0\n",
      "     BatchNorm2d-200            [-1, 1, 56, 56]               2\n",
      "            ReLU-201            [-1, 1, 56, 56]               0\n",
      "          Conv2d-202            [-1, 1, 56, 56]               2\n",
      "            Conv-203            [-1, 1, 56, 56]               0\n",
      "     BatchNorm2d-204            [-1, 1, 56, 56]               2\n",
      "            ReLU-205            [-1, 1, 56, 56]               0\n",
      "          Conv2d-206            [-1, 1, 56, 56]              10\n",
      "            Conv-207            [-1, 1, 56, 56]               0\n",
      "     BatchNorm2d-208            [-1, 1, 56, 56]               2\n",
      "            ReLU-209            [-1, 1, 56, 56]               0\n",
      "          Conv2d-210            [-1, 1, 56, 56]               2\n",
      "            Conv-211            [-1, 1, 56, 56]               0\n",
      "        Residual-212            [-1, 1, 56, 56]               0\n",
      "        Upsample-213          [-1, 1, 112, 112]               0\n",
      "       Hourglass-214          [-1, 1, 112, 112]               0\n",
      "     BatchNorm2d-215          [-1, 1, 112, 112]               2\n",
      "            ReLU-216          [-1, 1, 112, 112]               0\n",
      "          Conv2d-217          [-1, 1, 112, 112]               2\n",
      "            Conv-218          [-1, 1, 112, 112]               0\n",
      "     BatchNorm2d-219          [-1, 1, 112, 112]               2\n",
      "            ReLU-220          [-1, 1, 112, 112]               0\n",
      "          Conv2d-221          [-1, 1, 112, 112]              10\n",
      "            Conv-222          [-1, 1, 112, 112]               0\n",
      "     BatchNorm2d-223          [-1, 1, 112, 112]               2\n",
      "            ReLU-224          [-1, 1, 112, 112]               0\n",
      "          Conv2d-225          [-1, 1, 112, 112]               2\n",
      "            Conv-226          [-1, 1, 112, 112]               0\n",
      "        Residual-227          [-1, 1, 112, 112]               0\n",
      "        Upsample-228          [-1, 1, 224, 224]               0\n",
      "       Hourglass-229          [-1, 1, 224, 224]               0\n",
      "     BatchNorm2d-230          [-1, 1, 224, 224]               2\n",
      "            ReLU-231          [-1, 1, 224, 224]               0\n",
      "          Conv2d-232          [-1, 1, 224, 224]               2\n",
      "            Conv-233          [-1, 1, 224, 224]               0\n",
      "     BatchNorm2d-234          [-1, 1, 224, 224]               2\n",
      "            ReLU-235          [-1, 1, 224, 224]               0\n",
      "          Conv2d-236          [-1, 1, 224, 224]              10\n",
      "            Conv-237          [-1, 1, 224, 224]               0\n",
      "     BatchNorm2d-238          [-1, 1, 224, 224]               2\n",
      "            ReLU-239          [-1, 1, 224, 224]               0\n",
      "          Conv2d-240          [-1, 1, 224, 224]               2\n",
      "            Conv-241          [-1, 1, 224, 224]               0\n",
      "        Residual-242          [-1, 1, 224, 224]               0\n",
      "          Conv2d-243          [-1, 1, 224, 224]               2\n",
      "     BatchNorm2d-244          [-1, 1, 224, 224]               2\n",
      "            ReLU-245          [-1, 1, 224, 224]               0\n",
      "            Conv-246          [-1, 1, 224, 224]               0\n",
      "          Conv2d-247        [-1, 128, 224, 224]             256\n",
      "            Conv-248        [-1, 128, 224, 224]               0\n",
      "          Conv2d-249          [-1, 1, 224, 224]             129\n",
      "            Conv-250          [-1, 1, 224, 224]               0\n",
      "           Merge-251          [-1, 1, 224, 224]               0\n",
      "          Conv2d-252          [-1, 1, 224, 224]               2\n",
      "            Conv-253          [-1, 1, 224, 224]               0\n",
      "           Merge-254          [-1, 1, 224, 224]               0\n",
      "     BatchNorm2d-255          [-1, 1, 224, 224]               2\n",
      "            ReLU-256          [-1, 1, 224, 224]               0\n",
      "          Conv2d-257          [-1, 1, 224, 224]               2\n",
      "            Conv-258          [-1, 1, 224, 224]               0\n",
      "     BatchNorm2d-259          [-1, 1, 224, 224]               2\n",
      "            ReLU-260          [-1, 1, 224, 224]               0\n",
      "          Conv2d-261          [-1, 1, 224, 224]              10\n",
      "            Conv-262          [-1, 1, 224, 224]               0\n",
      "     BatchNorm2d-263          [-1, 1, 224, 224]               2\n",
      "            ReLU-264          [-1, 1, 224, 224]               0\n",
      "          Conv2d-265          [-1, 1, 224, 224]               2\n",
      "            Conv-266          [-1, 1, 224, 224]               0\n",
      "        Residual-267          [-1, 1, 224, 224]               0\n",
      "       MaxPool2d-268          [-1, 1, 112, 112]               0\n",
      "     BatchNorm2d-269          [-1, 1, 112, 112]               2\n",
      "            ReLU-270          [-1, 1, 112, 112]               0\n",
      "          Conv2d-271          [-1, 1, 112, 112]               2\n",
      "            Conv-272          [-1, 1, 112, 112]               0\n",
      "     BatchNorm2d-273          [-1, 1, 112, 112]               2\n",
      "            ReLU-274          [-1, 1, 112, 112]               0\n",
      "          Conv2d-275          [-1, 1, 112, 112]              10\n",
      "            Conv-276          [-1, 1, 112, 112]               0\n",
      "     BatchNorm2d-277          [-1, 1, 112, 112]               2\n",
      "            ReLU-278          [-1, 1, 112, 112]               0\n",
      "          Conv2d-279          [-1, 1, 112, 112]               2\n",
      "            Conv-280          [-1, 1, 112, 112]               0\n",
      "        Residual-281          [-1, 1, 112, 112]               0\n",
      "     BatchNorm2d-282          [-1, 1, 112, 112]               2\n",
      "            ReLU-283          [-1, 1, 112, 112]               0\n",
      "          Conv2d-284          [-1, 1, 112, 112]               2\n",
      "            Conv-285          [-1, 1, 112, 112]               0\n",
      "     BatchNorm2d-286          [-1, 1, 112, 112]               2\n",
      "            ReLU-287          [-1, 1, 112, 112]               0\n",
      "          Conv2d-288          [-1, 1, 112, 112]              10\n",
      "            Conv-289          [-1, 1, 112, 112]               0\n",
      "     BatchNorm2d-290          [-1, 1, 112, 112]               2\n",
      "            ReLU-291          [-1, 1, 112, 112]               0\n",
      "          Conv2d-292          [-1, 1, 112, 112]               2\n",
      "            Conv-293          [-1, 1, 112, 112]               0\n",
      "        Residual-294          [-1, 1, 112, 112]               0\n",
      "       MaxPool2d-295            [-1, 1, 56, 56]               0\n",
      "     BatchNorm2d-296            [-1, 1, 56, 56]               2\n",
      "            ReLU-297            [-1, 1, 56, 56]               0\n",
      "          Conv2d-298            [-1, 1, 56, 56]               2\n",
      "            Conv-299            [-1, 1, 56, 56]               0\n",
      "     BatchNorm2d-300            [-1, 1, 56, 56]               2\n",
      "            ReLU-301            [-1, 1, 56, 56]               0\n",
      "          Conv2d-302            [-1, 1, 56, 56]              10\n",
      "            Conv-303            [-1, 1, 56, 56]               0\n",
      "     BatchNorm2d-304            [-1, 1, 56, 56]               2\n",
      "            ReLU-305            [-1, 1, 56, 56]               0\n",
      "          Conv2d-306            [-1, 1, 56, 56]               2\n",
      "            Conv-307            [-1, 1, 56, 56]               0\n",
      "        Residual-308            [-1, 1, 56, 56]               0\n",
      "     BatchNorm2d-309            [-1, 1, 56, 56]               2\n",
      "            ReLU-310            [-1, 1, 56, 56]               0\n",
      "          Conv2d-311            [-1, 1, 56, 56]               2\n",
      "            Conv-312            [-1, 1, 56, 56]               0\n",
      "     BatchNorm2d-313            [-1, 1, 56, 56]               2\n",
      "            ReLU-314            [-1, 1, 56, 56]               0\n",
      "          Conv2d-315            [-1, 1, 56, 56]              10\n",
      "            Conv-316            [-1, 1, 56, 56]               0\n",
      "     BatchNorm2d-317            [-1, 1, 56, 56]               2\n",
      "            ReLU-318            [-1, 1, 56, 56]               0\n",
      "          Conv2d-319            [-1, 1, 56, 56]               2\n",
      "            Conv-320            [-1, 1, 56, 56]               0\n",
      "        Residual-321            [-1, 1, 56, 56]               0\n",
      "       MaxPool2d-322            [-1, 1, 28, 28]               0\n",
      "     BatchNorm2d-323            [-1, 1, 28, 28]               2\n",
      "            ReLU-324            [-1, 1, 28, 28]               0\n",
      "          Conv2d-325            [-1, 1, 28, 28]               2\n",
      "            Conv-326            [-1, 1, 28, 28]               0\n",
      "     BatchNorm2d-327            [-1, 1, 28, 28]               2\n",
      "            ReLU-328            [-1, 1, 28, 28]               0\n",
      "          Conv2d-329            [-1, 1, 28, 28]              10\n",
      "            Conv-330            [-1, 1, 28, 28]               0\n",
      "     BatchNorm2d-331            [-1, 1, 28, 28]               2\n",
      "            ReLU-332            [-1, 1, 28, 28]               0\n",
      "          Conv2d-333            [-1, 1, 28, 28]               2\n",
      "            Conv-334            [-1, 1, 28, 28]               0\n",
      "        Residual-335            [-1, 1, 28, 28]               0\n",
      "     BatchNorm2d-336            [-1, 1, 28, 28]               2\n",
      "            ReLU-337            [-1, 1, 28, 28]               0\n",
      "          Conv2d-338            [-1, 1, 28, 28]               2\n",
      "            Conv-339            [-1, 1, 28, 28]               0\n",
      "     BatchNorm2d-340            [-1, 1, 28, 28]               2\n",
      "            ReLU-341            [-1, 1, 28, 28]               0\n",
      "          Conv2d-342            [-1, 1, 28, 28]              10\n",
      "            Conv-343            [-1, 1, 28, 28]               0\n",
      "     BatchNorm2d-344            [-1, 1, 28, 28]               2\n",
      "            ReLU-345            [-1, 1, 28, 28]               0\n",
      "          Conv2d-346            [-1, 1, 28, 28]               2\n",
      "            Conv-347            [-1, 1, 28, 28]               0\n",
      "        Residual-348            [-1, 1, 28, 28]               0\n",
      "       MaxPool2d-349            [-1, 1, 14, 14]               0\n",
      "     BatchNorm2d-350            [-1, 1, 14, 14]               2\n",
      "            ReLU-351            [-1, 1, 14, 14]               0\n",
      "          Conv2d-352            [-1, 1, 14, 14]               2\n",
      "            Conv-353            [-1, 1, 14, 14]               0\n",
      "     BatchNorm2d-354            [-1, 1, 14, 14]               2\n",
      "            ReLU-355            [-1, 1, 14, 14]               0\n",
      "          Conv2d-356            [-1, 1, 14, 14]              10\n",
      "            Conv-357            [-1, 1, 14, 14]               0\n",
      "     BatchNorm2d-358            [-1, 1, 14, 14]               2\n",
      "            ReLU-359            [-1, 1, 14, 14]               0\n",
      "          Conv2d-360            [-1, 1, 14, 14]               2\n",
      "            Conv-361            [-1, 1, 14, 14]               0\n",
      "        Residual-362            [-1, 1, 14, 14]               0\n",
      "     BatchNorm2d-363            [-1, 1, 14, 14]               2\n",
      "            ReLU-364            [-1, 1, 14, 14]               0\n",
      "          Conv2d-365            [-1, 1, 14, 14]               2\n",
      "            Conv-366            [-1, 1, 14, 14]               0\n",
      "     BatchNorm2d-367            [-1, 1, 14, 14]               2\n",
      "            ReLU-368            [-1, 1, 14, 14]               0\n",
      "          Conv2d-369            [-1, 1, 14, 14]              10\n",
      "            Conv-370            [-1, 1, 14, 14]               0\n",
      "     BatchNorm2d-371            [-1, 1, 14, 14]               2\n",
      "            ReLU-372            [-1, 1, 14, 14]               0\n",
      "          Conv2d-373            [-1, 1, 14, 14]               2\n",
      "            Conv-374            [-1, 1, 14, 14]               0\n",
      "        Residual-375            [-1, 1, 14, 14]               0\n",
      "     BatchNorm2d-376            [-1, 1, 14, 14]               2\n",
      "            ReLU-377            [-1, 1, 14, 14]               0\n",
      "          Conv2d-378            [-1, 1, 14, 14]               2\n",
      "            Conv-379            [-1, 1, 14, 14]               0\n",
      "     BatchNorm2d-380            [-1, 1, 14, 14]               2\n",
      "            ReLU-381            [-1, 1, 14, 14]               0\n",
      "          Conv2d-382            [-1, 1, 14, 14]              10\n",
      "            Conv-383            [-1, 1, 14, 14]               0\n",
      "     BatchNorm2d-384            [-1, 1, 14, 14]               2\n",
      "            ReLU-385            [-1, 1, 14, 14]               0\n",
      "          Conv2d-386            [-1, 1, 14, 14]               2\n",
      "            Conv-387            [-1, 1, 14, 14]               0\n",
      "        Residual-388            [-1, 1, 14, 14]               0\n",
      "        Upsample-389            [-1, 1, 28, 28]               0\n",
      "       Hourglass-390            [-1, 1, 28, 28]               0\n",
      "     BatchNorm2d-391            [-1, 1, 28, 28]               2\n",
      "            ReLU-392            [-1, 1, 28, 28]               0\n",
      "          Conv2d-393            [-1, 1, 28, 28]               2\n",
      "            Conv-394            [-1, 1, 28, 28]               0\n",
      "     BatchNorm2d-395            [-1, 1, 28, 28]               2\n",
      "            ReLU-396            [-1, 1, 28, 28]               0\n",
      "          Conv2d-397            [-1, 1, 28, 28]              10\n",
      "            Conv-398            [-1, 1, 28, 28]               0\n",
      "     BatchNorm2d-399            [-1, 1, 28, 28]               2\n",
      "            ReLU-400            [-1, 1, 28, 28]               0\n",
      "          Conv2d-401            [-1, 1, 28, 28]               2\n",
      "            Conv-402            [-1, 1, 28, 28]               0\n",
      "        Residual-403            [-1, 1, 28, 28]               0\n",
      "        Upsample-404            [-1, 1, 56, 56]               0\n",
      "       Hourglass-405            [-1, 1, 56, 56]               0\n",
      "     BatchNorm2d-406            [-1, 1, 56, 56]               2\n",
      "            ReLU-407            [-1, 1, 56, 56]               0\n",
      "          Conv2d-408            [-1, 1, 56, 56]               2\n",
      "            Conv-409            [-1, 1, 56, 56]               0\n",
      "     BatchNorm2d-410            [-1, 1, 56, 56]               2\n",
      "            ReLU-411            [-1, 1, 56, 56]               0\n",
      "          Conv2d-412            [-1, 1, 56, 56]              10\n",
      "            Conv-413            [-1, 1, 56, 56]               0\n",
      "     BatchNorm2d-414            [-1, 1, 56, 56]               2\n",
      "            ReLU-415            [-1, 1, 56, 56]               0\n",
      "          Conv2d-416            [-1, 1, 56, 56]               2\n",
      "            Conv-417            [-1, 1, 56, 56]               0\n",
      "        Residual-418            [-1, 1, 56, 56]               0\n",
      "        Upsample-419          [-1, 1, 112, 112]               0\n",
      "       Hourglass-420          [-1, 1, 112, 112]               0\n",
      "     BatchNorm2d-421          [-1, 1, 112, 112]               2\n",
      "            ReLU-422          [-1, 1, 112, 112]               0\n",
      "          Conv2d-423          [-1, 1, 112, 112]               2\n",
      "            Conv-424          [-1, 1, 112, 112]               0\n",
      "     BatchNorm2d-425          [-1, 1, 112, 112]               2\n",
      "            ReLU-426          [-1, 1, 112, 112]               0\n",
      "          Conv2d-427          [-1, 1, 112, 112]              10\n",
      "            Conv-428          [-1, 1, 112, 112]               0\n",
      "     BatchNorm2d-429          [-1, 1, 112, 112]               2\n",
      "            ReLU-430          [-1, 1, 112, 112]               0\n",
      "          Conv2d-431          [-1, 1, 112, 112]               2\n",
      "            Conv-432          [-1, 1, 112, 112]               0\n",
      "        Residual-433          [-1, 1, 112, 112]               0\n",
      "        Upsample-434          [-1, 1, 224, 224]               0\n",
      "       Hourglass-435          [-1, 1, 224, 224]               0\n",
      "     BatchNorm2d-436          [-1, 1, 224, 224]               2\n",
      "            ReLU-437          [-1, 1, 224, 224]               0\n",
      "          Conv2d-438          [-1, 1, 224, 224]               2\n",
      "            Conv-439          [-1, 1, 224, 224]               0\n",
      "     BatchNorm2d-440          [-1, 1, 224, 224]               2\n",
      "            ReLU-441          [-1, 1, 224, 224]               0\n",
      "          Conv2d-442          [-1, 1, 224, 224]              10\n",
      "            Conv-443          [-1, 1, 224, 224]               0\n",
      "     BatchNorm2d-444          [-1, 1, 224, 224]               2\n",
      "            ReLU-445          [-1, 1, 224, 224]               0\n",
      "          Conv2d-446          [-1, 1, 224, 224]               2\n",
      "            Conv-447          [-1, 1, 224, 224]               0\n",
      "        Residual-448          [-1, 1, 224, 224]               0\n",
      "          Conv2d-449          [-1, 1, 224, 224]               2\n",
      "     BatchNorm2d-450          [-1, 1, 224, 224]               2\n",
      "            ReLU-451          [-1, 1, 224, 224]               0\n",
      "            Conv-452          [-1, 1, 224, 224]               0\n",
      "          Conv2d-453        [-1, 128, 224, 224]             256\n",
      "            Conv-454        [-1, 128, 224, 224]               0\n",
      "          Conv2d-455          [-1, 9, 112, 112]           9,225\n",
      "          Conv2d-456            [-1, 9, 56, 56]             333\n",
      "          Conv2d-457            [-1, 3, 56, 56]              30\n",
      "        Upsample-458          [-1, 3, 224, 224]               0\n",
      "================================================================\n",
      "Total params: 126,785\n",
      "Trainable params: 126,785\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.19\n",
      "Forward/backward pass size (MB): 419.83\n",
      "Params size (MB): 0.48\n",
      "Estimated Total Size (MB): 420.50\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model.cuda(), input_size=(1,224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "DSIM",
   "language": "python",
   "name": "dsim"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
